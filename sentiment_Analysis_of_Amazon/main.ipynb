{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1 : Importing necessary Libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # for working with arrays,linear algebra, matrices \n",
    "import pandas as pd # for data manipulation \n",
    "import nltk # for static nlp \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re #raise exception if occurs\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud # highlight popular words for analysis \n",
    "import seaborn as sns # for data visualization \n",
    "import matplotlib.pyplot as plt # for data visualization \n",
    "import cufflinks as cf #links matplotlib with pandas  \n",
    "#to display plots inside notebook, basically for offline graphics \n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected = True)\n",
    "cf.go_offline();\n",
    "# plotly defines fundamental classes \n",
    "import plotly.graph_objs as go \n",
    "from plotly.subplots import make_subplots \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2:  Data manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>Hyoun Kim \"Faluzure\"</td>\n",
       "      <td>5</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>05-01-2013</td>\n",
       "      <td>702</td>\n",
       "      <td>1952</td>\n",
       "      <td>68</td>\n",
       "      <td>2020</td>\n",
       "      <td>1884</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>NLee the Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>26-09-2012</td>\n",
       "      <td>803</td>\n",
       "      <td>1428</td>\n",
       "      <td>77</td>\n",
       "      <td>1505</td>\n",
       "      <td>1351</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.936519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>SkincareCEO</td>\n",
       "      <td>1</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>08-05-2013</td>\n",
       "      <td>579</td>\n",
       "      <td>1568</td>\n",
       "      <td>126</td>\n",
       "      <td>1694</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>0.912139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Amazon Customer \"Kelly\"</td>\n",
       "      <td>1</td>\n",
       "      <td>If your card gets hot enough to be painful, it...</td>\n",
       "      <td>09-02-2012</td>\n",
       "      <td>1033</td>\n",
       "      <td>422</td>\n",
       "      <td>73</td>\n",
       "      <td>495</td>\n",
       "      <td>349</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.818577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>Twister</td>\n",
       "      <td>5</td>\n",
       "      <td>Sandisk announcement of the first 128GB micro ...</td>\n",
       "      <td>03-07-2014</td>\n",
       "      <td>158</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.808109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 reviewerName  overall  \\\n",
       "2031     Hyoun Kim \"Faluzure\"        5   \n",
       "3449        NLee the Engineer        5   \n",
       "4212              SkincareCEO        1   \n",
       "317   Amazon Customer \"Kelly\"        1   \n",
       "4672                  Twister        5   \n",
       "\n",
       "                                             reviewText  reviewTime  day_diff  \\\n",
       "2031  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...  05-01-2013       702   \n",
       "3449  I have tested dozens of SDHC and micro-SDHC ca...  26-09-2012       803   \n",
       "4212  NOTE:  please read the last update (scroll to ...  08-05-2013       579   \n",
       "317   If your card gets hot enough to be painful, it...  09-02-2012      1033   \n",
       "4672  Sandisk announcement of the first 128GB micro ...  03-07-2014       158   \n",
       "\n",
       "      helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "2031         1952          68        2020                1884   \n",
       "3449         1428          77        1505                1351   \n",
       "4212         1568         126        1694                1442   \n",
       "317           422          73         495                 349   \n",
       "4672           45           4          49                  41   \n",
       "\n",
       "      score_average_rating  wilson_lower_bound  \n",
       "2031              0.966337            0.957544  \n",
       "3449              0.948837            0.936519  \n",
       "4212              0.925620            0.912139  \n",
       "317               0.852525            0.818577  \n",
       "4672              0.918367            0.808109  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(\"wilson_lower_bound\", ascending=False)\n",
    "df.drop('Unnamed: 0', inplace= True, axis= 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **sort** : sorts the value of wilson_lower_bound with highest value at top \n",
    "- **drop** : deletes the column named `Unnamed: 0 ` \n",
    "- **inplace=True** : Make modification in original dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Handling Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze missing values in a DataFrame\n",
    "def missing_values_analysis(df):\n",
    "    # Identify columns with missing values\n",
    "    na_columns_ = [col for col in df.columns if df[col].isnull().sum() > 0]\n",
    "    \n",
    "    # Count missing values and calculate the ratio\n",
    "    n_miss = df[na_columns_].isnull().sum().sort_values(ascending=True)\n",
    "    ratio_ = (df[na_columns_].isnull().sum() / df.shape[0] * 100).sort_values(ascending=True)\n",
    "    \n",
    "    # Create a DataFrame to display missing values and ratios\n",
    "    missing_df = pd.concat([n_miss, np.round(ratio_, 2)], axis=1, keys=['Missing values', 'Ratio'])\n",
    "    \n",
    "    return missing_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3. Function to check and summarize DataFrame information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Shape~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Rows: 4915\n",
      "Columns: 11\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Types~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "reviewerName             object\n",
      "overall                   int64\n",
      "reviewText               object\n",
      "reviewTime               object\n",
      "day_diff                  int64\n",
      "helpful_yes               int64\n",
      "helpful_no                int64\n",
      "total_vote                int64\n",
      "score_pos_neg_diff        int64\n",
      "score_average_rating    float64\n",
      "wilson_lower_bound      float64\n",
      "dtype: object\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "              Missing values  Ratio\n",
      "reviewerName               1   0.02\n",
      "reviewText                 1   0.02\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Duplicated Values~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Quantiles~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "                       count        mean         std    min    25%    50%  \\\n",
      "overall               4915.0    4.587589    0.996845    1.0    5.0    5.0   \n",
      "day_diff              4915.0  437.367040  209.439871    1.0  281.0  431.0   \n",
      "helpful_yes           4915.0    1.311089   41.619161    0.0    0.0    0.0   \n",
      "helpful_no            4915.0    0.210376    4.023296    0.0    0.0    0.0   \n",
      "total_vote            4915.0    1.521465   44.123095    0.0    0.0    0.0   \n",
      "score_pos_neg_diff    4915.0    1.100712   39.367949 -130.0    0.0    0.0   \n",
      "score_average_rating  4915.0    0.075468    0.256062    0.0    0.0    0.0   \n",
      "wilson_lower_bound    4915.0    0.020053    0.077187    0.0    0.0    0.0   \n",
      "\n",
      "                        75%          max  \n",
      "overall                 5.0     5.000000  \n",
      "day_diff              601.0  1064.000000  \n",
      "helpful_yes             0.0  1952.000000  \n",
      "helpful_no              0.0   183.000000  \n",
      "total_vote              0.0  2020.000000  \n",
      "score_pos_neg_diff      0.0  1884.000000  \n",
      "score_average_rating    0.0     1.000000  \n",
      "wilson_lower_bound      0.0     0.957544  \n"
     ]
    }
   ],
   "source": [
    "# Function to check and summarize DataFrame information\n",
    "def check_dataframe(df, head=5, tail=5):\n",
    "    # Display shape of the DataFrame\n",
    "    print(\"Shape\".center(82, '~'))\n",
    "    print(\"Rows: {}\".format(df.shape[0]))\n",
    "    print(\"Columns: {}\".format(df.shape[1]))\n",
    "    \n",
    "    # Display data types of columns\n",
    "    print(\"Types\".center(82, '~'))\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Display missing values analysis\n",
    "    print(\"\".center(82, '~'))\n",
    "    print(missing_values_analysis(df))\n",
    "    \n",
    "    # Display number of duplicated values\n",
    "    print(\"Duplicated Values\".center(83, '~'))\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    # Display quantiles of the DataFrame\n",
    "    print(\"Quantiles\".center(82, '~'))\n",
    "    print(df.describe().T)  # Use df.describe() instead of df.quantile()\n",
    "\n",
    "# Example usage\n",
    "check_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking a particular row comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[ UPDATE - 6/19/2014 ]]So my lovely wife bought me a Samsung Galaxy Tab 4 for Father\\'s Day and I\\'ve been loving it ever since.  Just as other with Samsung products, the Galaxy Tab 4 has the ability to add a microSD card to expand the memory on the device.  Since it\\'s been over a year, I decided to do some more research to see if SanDisk offered anything new.  As of 6/19/2014, their product lineup for microSD cards from worst to best (performance-wise) are the as follows:SanDiskSanDisk UltraSanDisk Ultra PLUSSanDisk ExtremeSanDisk Extreme PLUSSanDisk Extreme PRONow, the difference between all of these cards are simply the speed in which you can read/write data to the card.  Yes, the published rating of most all these cards (except the SanDisk regular) are Class 10/UHS-I but that\\'s just a rating... Actual real world performance does get better with each model, but with faster cards come more expensive prices.  Since Amazon doesn\\'t carry the Ultra PLUS model of microSD card, I had to do direct comparisons between the SanDisk Ultra ($34.27), Extreme ($57.95), and Extreme PLUS ($67.95).As mentioned in my earlier review, I purchased the SanDisk Ultra for my Galaxy S4.  My question was, did I want to pay over $20 more for a card that is faster than the one I already owned?  Or I could pay almost double to get SanDisk\\'s 2nd-most fastest microSD card.The Ultra works perfectly fine for my style of usage (storing/capturing pictures & HD video and movie playback) on my phone.  So in the end, I ended up just buying another SanDisk Ultra 64GB card.  I use my cell phone *more* than I do my tablet and if the card is good enough for my phone, it\\'s good enough for my tablet.  I don\\'t own a 4K HD camera or anything like that, so I honestly didn\\'t see a need to get one of the faster cards at this time.I am now a proud owner of 2 SanDisk Ultra cards and have absolutely 0 issues with it in my Samsung devices.[[ ORIGINAL REVIEW - 5/1/2013 ]]I haven\\'t had to buy a microSD card in a long time. The last time I bought one was for my cell phone over 2 years ago. But since my cellular contract was up, I knew I would have to get a newer card in addition to my new phone, the Samsung Galaxy S4. Reason for this is because I knew my small 16GB microSD card wasn\\'t going to cut it.Doing research on the Galaxy S4, I wanted to get the best card possible that had decent capacity (32 GB or greater). This led me to find that the Galaxy S4 supports the microSDXC Class 10 UHS-I card, which is the fastest possible given that class. Searching for that specifically on Amazon gave me results of only 3 vendors (as of April) that makes these microSDXC Class 10 UHS-1 cards. They are Sandisk (the majority), Samsung and Lexar. Nobody else makes these that are sold on Amazon.Seeing how SanDisk is a pretty good name out of the 3 (I\\'ve used them the most), I decided upon the SanDisk because Lexar was overpriced and the Samsung one was overpriced (as well as not eligible for Amazon Prime).But the scary thing is that when you filter by the SanDisk, you literally get DOZENS of options. All of them have different model numbers, different sizes, etc. Then there\\'s that confusion of what\\'s the difference between SDHC & SDXC?SDHC vs SDXC:SDHC stand for \"Secure Digital High Capacity\" and SDXC stands for \"Secure Digital eXtended Capacity\". Essentially these two cards are the same with the exception that SDHC only supports capcities up to 32GB and is formated with the FAT32 file system. The SDXC cards are formatted with the exFAT file system. If you use an SDXC card in a device, it must support that file system, otherwise it may not be recognizable and/or you have to reformat the card to FAT32.FAT32 vs exFAT:The differences between the two file systems means that FAT32 has a maximum file size of 4GB, limited by that file system. exFAT on the otherhand, supports file sizes up to 2TB (terabytes). The only thing you need to know here really is that it\\'s possible your device doesn\\'t support exFAT. If that\\'s the case, just reformat it to FAT32. REMEMBER FORMATTING ERASES ALL DATA!To clarify the model numbers, I I hopped over to the SanDisk official webpage. What I found there is that they offer two \"highspeed\" options for SanDisk cards. These are SanDisk Extreme Pro and SanDisk Ultra. SanDisk Extreme Pro is a line that supports read speeds up to 95MB/sec, however they are SDHC only. To make things worse, they are currently only available in 16GB & 8GB capacities. Since one of my requirements was to have a lot of storage, I ruled these out.The remaining devices listed on Amazon\\'s search were the SanDisk Ultra line. But here, confusion sets in because SanDisk separates these cards to two different devices. Cameras & mobile devices. Is there a real difference between the two or is this just a marketing stunt? Unfortunately I\\'m not sure but I do know the price difference between the two range from a couple cents to a few dollars. Since I wasn\\'t sure, I opted for the one specifically targeted for mobile devices (just in case there is some kind of compatibility issue). To find the exact model number, I would go to Sandisk\\'s webpage (sandisk.com) and compare their existing product lineup. From there, you get exact model numbers and you can then search Amazon for these model numbers. That is how I got mine (SDSDQUA-064G).As for speed tests, I haven\\'t run any specific testing, but copying 8 GB worth of data from my PC to the card literally took just a few minutes.One last note is that Amazon attaches additional characters to the end (for example SDSDQUA-064G-AFFP-A vs SDSDQUA-064G-U46A). The difference between the two is that the \"AFFP-A\" means \"Amazon Frustration Free Packaging\". Other than that, these are exactly the same.  If you\\'re wondering what I got (and want to use it in your Galaxy S4), I got the SDSDQUA-064G-u46A and it works like charm.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_example = df.reviewText[2031]\n",
    "review_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the particular row comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['updatesomylovelywifeboughtmeasamsunggalaxytabforfathersdayandivebeenlovingiteversincejustasotherwithsamsungproductsthegalaxytabhastheabilitytoaddamicrosdcardtoexpandthememoryonthedevicesinceitsbeenoverayearidecidedtodosomemoreresearchtoseeifsandiskofferedanythingnewasoftheirproductlineupformicrosdcardsfromworsttobestperformancewisearetheasfollowssandisksandiskultrasandiskultraplussandiskextremesandiskextremeplussandiskextremepronowthedifferencebetweenallofthesecardsaresimplythespeedinwhichyoucanreadwritedatatothecardyesthepublishedratingofmostallthesecardsexceptthesandiskregularareclassuhsibutthatsjustaratingactualrealworldperformancedoesgetbetterwitheachmodelbutwithfastercardscomemoreexpensivepricessinceamazondoesntcarrytheultraplusmodelofmicrosdcardihadtododirectcomparisonsbetweenthesandiskultraextremeandextremeplusasmentionedinmyearlierreviewipurchasedthesandiskultraformygalaxysmyquestionwasdidiwanttopayovermoreforacardthatisfasterthantheoneialreadyownedoricouldpayalmostdoubletogetsandisksndmostfastestmicrosdcardtheultraworksperfectlyfineformystyleofusagestoringcapturingpictureshdvideoandmovieplaybackonmyphonesointheendiendedupjustbuyinganothersandiskultragbcardiusemycellphonemorethanidomytabletandifthecardisgoodenoughformyphoneitsgoodenoughformytabletidontownakhdcameraoranythinglikethatsoihonestlydidntseeaneedtogetoneofthefastercardsatthistimeiamnowaproudownerofsandiskultracardsandhaveabsolutelyissueswithitinmysamsungdevicesoriginalreviewihaventhadtobuyamicrosdcardinalongtimethelasttimeiboughtonewasformycellphoneoveryearsagobutsincemycellularcontractwasupiknewiwouldhavetogetanewercardinadditiontomynewphonethesamsunggalaxysreasonforthisisbecauseiknewmysmallgbmicrosdcardwasntgoingtocutitdoingresearchonthegalaxysiwantedtogetthebestcardpossiblethathaddecentcapacitygborgreaterthisledmetofindthatthegalaxyssupportsthemicrosdxcclassuhsicardwhichisthefastestpossiblegiventhatclasssearchingforthatspecificallyonamazongavemeresultsofonlyvendorsasofaprilthatmakesthesemicrosdxcclassuhscardstheyaresandiskthemajoritysamsungandlexarnobodyelsemakesthesethataresoldonamazonseeinghowsandiskisaprettygoodnameoutoftheiveusedthemthemostidecideduponthesandiskbecauselexarwasoverpricedandthesamsungonewasoverpricedaswellasnoteligibleforamazonprimebutthescarythingisthatwhenyoufilterbythesandiskyouliterallygetdozensofoptionsallofthemhavedifferentmodelnumbersdifferentsizesetcthentheresthatconfusionofwhatsthedifferencebetweensdhcsdxcsdhcvssdxcsdhcstandforsecuredigitalhighcapacityandsdxcstandsforsecuredigitalextendedcapacityessentiallythesetwocardsarethesamewiththeexceptionthatsdhconlysupportscapcitiesuptogbandisformatedwiththefatfilesystemthesdxccardsareformattedwiththeexfatfilesystemifyouuseansdxccardinadeviceitmustsupportthatfilesystemotherwiseitmaynotberecognizableandoryouhavetoreformatthecardtofatfatvsexfatthedifferencesbetweenthetwofilesystemsmeansthatfathasamaximumfilesizeofgblimitedbythatfilesystemexfatontheotherhandsupportsfilesizesuptotbterabytestheonlythingyouneedtoknowherereallyisthatitspossibleyourdevicedoesntsupportexfatifthatsthecasejustreformatittofatrememberformattingerasesalldatatoclarifythemodelnumbersiihoppedovertothesandiskofficialwebpagewhatifoundthereisthattheyoffertwohighspeedoptionsforsandiskcardsthesearesandiskextremeproandsandiskultrasandiskextremeproisalinethatsupportsreadspeedsuptombsechowevertheyaresdhconlytomakethingsworsetheyarecurrentlyonlyavailableingbgbcapacitiessinceoneofmyrequirementswastohavealotofstorageiruledtheseouttheremainingdeviceslistedonamazonssearchwerethesandiskultralinebuthereconfusionsetsinbecausesandiskseparatesthesecardstotwodifferentdevicescamerasmobiledevicesistherearealdifferencebetweenthetwooristhisjustamarketingstuntunfortunatelyimnotsurebutidoknowthepricedifferencebetweenthetworangefromacouplecentstoafewdollarssinceiwasntsureioptedfortheonespecificallytargetedformobiledevicesjustincasethereissomekindofcompatibilityissuetofindtheexactmodelnumberiwouldgotosandiskswebpagesandiskcomandcomparetheirexistingproductlineupfromthereyougetexactmodelnumbersandyoucanthensearchamazonforthesemodelnumbersthatishowigotminesdsdquagasforspeedtestsihaventrunanyspecifictestingbutcopyinggbworthofdatafrommypctothecardliterallytookjustafewminutesonelastnoteisthatamazonattachesadditionalcharacterstotheendforexamplesdsdquagaffpavssdsdquaguathedifferencebetweenthetwoisthattheaffpameansamazonfrustrationfreepackagingotherthanthattheseareexactlythesameifyourewonderingwhatigotandwanttouseitinyourgalaxysigotthesdsdquaguaanditworkslikecharm']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all the puntucation from particular comment \n",
    "review_example = re.sub(\"[^a-zA-Z]\",\"\", review_example)\n",
    "\n",
    "# converting all to lowercase and splitting them in new line \n",
    "review_example = review_example.lower().split()\n",
    "\n",
    "review_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the same changes to the whole dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>Hyoun Kim \"Faluzure\"</td>\n",
       "      <td>5</td>\n",
       "      <td>update               so my lovely wife boug...</td>\n",
       "      <td>05-01-2013</td>\n",
       "      <td>702</td>\n",
       "      <td>1952</td>\n",
       "      <td>68</td>\n",
       "      <td>2020</td>\n",
       "      <td>1884</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>NLee the Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>i have tested dozens of sdhc and micro sdhc ca...</td>\n",
       "      <td>26-09-2012</td>\n",
       "      <td>803</td>\n",
       "      <td>1428</td>\n",
       "      <td>77</td>\n",
       "      <td>1505</td>\n",
       "      <td>1351</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.936519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4212</th>\n",
       "      <td>SkincareCEO</td>\n",
       "      <td>1</td>\n",
       "      <td>note   please read the last update  scroll to ...</td>\n",
       "      <td>08-05-2013</td>\n",
       "      <td>579</td>\n",
       "      <td>1568</td>\n",
       "      <td>126</td>\n",
       "      <td>1694</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>0.912139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Amazon Customer \"Kelly\"</td>\n",
       "      <td>1</td>\n",
       "      <td>if your card gets hot enough to be painful  it...</td>\n",
       "      <td>09-02-2012</td>\n",
       "      <td>1033</td>\n",
       "      <td>422</td>\n",
       "      <td>73</td>\n",
       "      <td>495</td>\n",
       "      <td>349</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.818577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>Twister</td>\n",
       "      <td>5</td>\n",
       "      <td>sandisk announcement of the first    gb micro ...</td>\n",
       "      <td>03-07-2014</td>\n",
       "      <td>158</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.808109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 reviewerName  overall  \\\n",
       "2031     Hyoun Kim \"Faluzure\"        5   \n",
       "3449        NLee the Engineer        5   \n",
       "4212              SkincareCEO        1   \n",
       "317   Amazon Customer \"Kelly\"        1   \n",
       "4672                  Twister        5   \n",
       "\n",
       "                                             reviewText  reviewTime  day_diff  \\\n",
       "2031     update               so my lovely wife boug...  05-01-2013       702   \n",
       "3449  i have tested dozens of sdhc and micro sdhc ca...  26-09-2012       803   \n",
       "4212  note   please read the last update  scroll to ...  08-05-2013       579   \n",
       "317   if your card gets hot enough to be painful  it...  09-02-2012      1033   \n",
       "4672  sandisk announcement of the first    gb micro ...  03-07-2014       158   \n",
       "\n",
       "      helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "2031         1952          68        2020                1884   \n",
       "3449         1428          77        1505                1351   \n",
       "4212         1568         126        1694                1442   \n",
       "317           422          73         495                 349   \n",
       "4672           45           4          49                  41   \n",
       "\n",
       "      score_average_rating  wilson_lower_bound  \n",
       "2031              0.966337            0.957544  \n",
       "3449              0.948837            0.936519  \n",
       "4212              0.925620            0.912139  \n",
       "317               0.852525            0.818577  \n",
       "4672              0.918367            0.808109  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = lambda x: re.sub(\"[^a-zA-Z]\", ' ', str(x))\n",
    "df[\"reviewText\"] = df[\"reviewText\"].map(rt)\n",
    "df[\"reviewText\"] = df[\"reviewText\"].str.lower()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Using TextBlob for polarity and subjectivity\n",
    "df[['polarity', 'subjectivity']] = df['reviewText'].apply(lambda text: pd.Series(TextBlob(str(text)).sentiment))\n",
    "\n",
    "# Using VaderSentiment for sentiment analysis\n",
    "for index, row in df['reviewText'].items():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(str(row))\n",
    "    \n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    \n",
    "    if neg > pos: \n",
    "        df.loc[index, 'sentiment'] = \"Negative\"\n",
    "    elif pos > neg: \n",
    "        df.loc[index, 'sentiment'] = \"Positive\"\n",
    "    else:\n",
    "        df.loc[index, 'sentiment'] = \"Neutral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"sentiment\"] ==  \"Positive\"].sort_values(\"wilson_lower_bound\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catagorize data into positive neagative and neutral \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize sentiment distribution using both bar plot and pie chart\n",
    "def plot_combined_chart(sentiment_summary):\n",
    "    \"\"\"\n",
    "    Plots are a combined chart with both bar plot and pie chart to visualize the distribution of sentiments.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Pie chart\n",
    "    labels = sentiment_summary['sentiment']\n",
    "    sizes = sentiment_summary['Count']\n",
    "    colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax1.set_title('Sentiment Distribution (Pie Chart)')\n",
    "\n",
    "    # Bar plot\n",
    "    ax2.bar(sentiment_summary['sentiment'], sentiment_summary['Count'], color=['lightcoral', 'lightblue', 'lightgreen'])\n",
    "    ax2.set_xlabel('Sentiment')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Sentiment Distribution (Bar Plot)')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the combined chart\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "sentiment_summary = categorical_variable_summary(df, 'sentiment')\n",
    "plot_combined_chart(sentiment_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
